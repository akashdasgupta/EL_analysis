{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "qualified-proportion",
   "metadata": {},
   "source": [
    "# PL ANALYSIS\n",
    "* Hi! This notebook is for analysis of PL data. \n",
    "* I am assuming your data is organised in this format: [Path to all the data]\\\\[name of sample]\\\\[Pixel number]. \n",
    "    * These will have a bunch of images, a folder called 'refs', a folder called 'white'and a csv file called IV\n",
    "    \n",
    "### Some instructions: \n",
    "* Please run each cell in order, following the instructions\n",
    "* Have at hand your datapath, and the path you would like to save the data in\n",
    "    * The outputs will sometimes show here but all of it is saved in the folder you provide\n",
    "* Press cntrl+enter to run a cell\n",
    "* When prompted enter information into the feilds and press enter\n",
    "* If you go back and re run a cell, that's fine but you have to run every cell after that again, and in order\n",
    "\n",
    "This might break if all these files are not there! If you want to edit this code definately go ahead, a bunch of the functions live in seperate .py files, BUT please make a copy!!!\n",
    "\n",
    "SEE LAST PANEL FOR BASIC HELP IF YOU HAVE DIFFICULTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports:\n",
    "from external_imports import *\n",
    "from image_process import *\n",
    "from general_data_process import *\n",
    "from reconstruct_jv import *\n",
    "\n",
    "# For parallel processing\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Plot parameters\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "matplotlib.rcParams['font.size'] = 12\n",
    "matplotlib.rcParams['font.family'] = \"Century Gothic\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-entertainment",
   "metadata": {},
   "source": [
    "### Data + Save folders\n",
    "* Copy and paste the path to your data bellow, as well as where you would like the output files from this analysis to be saved\n",
    "* Don't remove the \" \" marks, or the 'r' in front of them, that's important!\n",
    "* Again, make sure your data is organised in the \"[Path to all the data]\\[name of sample]\\[Pixel number]\" format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = r\"C:\\Users\\akashdasgupta\\OneDrive - Nexus365\\Data\\EL_setup\\actual_but_reduced\"\n",
    "savepath = r\"C:\\Users\\akashdasgupta\\OneDrive - Nexus365\\Data\\EL_setup\\actual_processed\"\n",
    "\n",
    "path_db = path_process(datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-portable",
   "metadata": {},
   "source": [
    "### STEP 3: Enter bandgaps\n",
    "* We need bandgaps for the calculations\n",
    "* Run bellow, enter as it prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandgaps = {}\n",
    "for key in path_db.keys():\n",
    "    if key.lower() != 'white':\n",
    "        string = \"What's the bandgap of \"+key+\" in eV?: \"\n",
    "        bandgap = float(input(string))\n",
    "        bandgaps[key] = bandgap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-louis",
   "metadata": {},
   "source": [
    "### STEP 5: Calculate corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{datapath}\\\\white_params.csv\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        if row[0].lower() == \"exposure\":\n",
    "            white_exposure = float(row[1])\n",
    "        elif row[0].lower() == \"flux scale\":\n",
    "            white_flux = float(row[1])\n",
    "        \n",
    "correction_db = {}\n",
    "for key in path_db.keys(): \n",
    "    bandgap = bandgaps[key]\n",
    "    correction = white_over_cell_correction(white_exposure, ledspecf, np.vectorize(BBf_cellf), \n",
    "                                            bandgap, camqef, lenscalf, 0.99, filtcalf)\n",
    "\n",
    "    correction_db[key] = correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-spencer",
   "metadata": {},
   "source": [
    "## Different analysis modules:\n",
    "* The following will be different cells that do different bits of analysis, just run the ones you want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-definition",
   "metadata": {},
   "source": [
    "### STEP 6.1 (opt.): Whole image averaged JV\n",
    "* Calculate Psudo J/V and Sun's Voc JV averaging over whole cropped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-charter",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in path_db.keys():\n",
    "    for pix in path_db[key]:     \n",
    "\n",
    "        path = f\"{datapath}\\\\{key}\\\\{pix}\"\n",
    "        savepath_i = f\"{savepath}\\\\{key}\\\\{pix}\"\n",
    "\n",
    "        bandgap = bandgaps[key]\n",
    "\n",
    "        white_mean_scaled = np.mean(np.load(f\"{datapath}\\\\{key}\\\\{pix}\\\\white.npy\"))/(correction_db[key]*white_flux)\n",
    "        flux_1sun = j1sunf(bandgap)\n",
    "        voc_rad = vocradf(bandgap)\n",
    "\n",
    "        num_suns, rrs, Vs, Js, fluxes = whole_image_jv(path, flux_1sun, voc_rad, white_mean_scaled)\n",
    "\n",
    "        \n",
    "        ##########\n",
    "        # Suns voc plot\n",
    "        suns_voc_V = []\n",
    "        with open(f\"{datapath}\\\\{key}\\\\{pix}\\\\oc\\\\source_meter.csv\",'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            for row in reader:\n",
    "                suns_voc_V.append(float(row[0]))\n",
    "        suns_voc_V = np.array(suns_voc_V)\n",
    "        num_suns_suns_voc = deepcopy(num_suns)\n",
    "        num_suns_suns_voc.sort()\n",
    "        num_suns_suns_voc = np.flip(num_suns_suns_voc)\n",
    "        \n",
    "        #####\n",
    "        # Plot\n",
    "        \n",
    "        plt.scatter(-Vs, Js, color='k', label = 'Reconstructed')\n",
    "        plt.plot(suns_voc_V, 1-num_suns_suns_voc, color='r', label = \"Sun's Voc measurement\")\n",
    "        \n",
    "        plt.xlim((-1.3,-0.3))      \n",
    "        plt.ylim((-1,1))\n",
    "        plt.axhline(0,color='k')\n",
    "        \n",
    "        plt.legend(frameon=False)\n",
    "        plt.xlabel(\"Voltage (V)\")\n",
    "        plt.ylabel(\"J/J$_{sc}$\")\n",
    "        plt.title(f\"{key}, Pixel {pix}\")\n",
    "        \n",
    "        if not os.path.isdir(f\"{savepath_i}\\\\whole_im_reconstructed_jvs\"):\n",
    "            os.makedirs(f\"{savepath_i}\\\\whole_im_reconstructed_jvs\")\n",
    "        plt.savefig(f\"{savepath_i}\\\\whole_im_reconstructed_jvs\\\\PL_reconstructed.png\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        ###############\n",
    "        # saves as csv\n",
    "        \n",
    "\n",
    "        with open(f\"{savepath_i}\\\\whole_im_reconstructed_jvs\\\\PL_reconstructed.csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for row in zip(-Vs, Js):\n",
    "                writer.writerow(row)\n",
    "        with open(f\"{savepath_i}\\\\whole_im_reconstructed_jvs\\\\suns_voc.csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for row in zip(suns_voc_V, 1-num_suns_suns_voc):\n",
    "                writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-empty",
   "metadata": {},
   "source": [
    "### STEP 6.2(opt.): Whole image spatially resolved JV\n",
    "* Calculate Psudo J/V per pixel, making a set of images of some current, with a spatial voltage map \n",
    "* Option to interpolate this, and make images at constant voltage, mapping current at that voltage per pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-bottom",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in path_db.keys():\n",
    "    for pix in path_db[key]:     \n",
    "\n",
    "        path = f\"{datapath}\\\\{key}\\\\{pix}\"\n",
    "        savepath_i = f\"{savepath}\\\\{key}\\\\{pix}\"\n",
    "\n",
    "        bandgap = bandgaps[key]\n",
    "\n",
    "        white_mean_scaled = np.mean(np.load(f\"{datapath}\\\\{key}\\\\{pix}\\\\white.npy\"))/(correction_db[key]*white_flux)\n",
    "        flux_1sun = j1sunf(bandgap)\n",
    "        voc_rad = vocradf(bandgap)\n",
    "\n",
    "        array_jv(path, savepath_i, flux_1sun, voc_rad, white_mean_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to save the images\n",
    "for key in path_db.keys():\n",
    "    for pix in path_db[key]:\n",
    "        path = f\"{savepath}\\\\{key}\\\\{pix}\\\\V\"\n",
    "        files = find_npy(path)\n",
    "\n",
    "        for file in files:\n",
    "            savefile_name = '_'.join(file.split('_')[:-1])+'.png'\n",
    "            fig, ax = plt.subplots()\n",
    "            J_led = 1 - float(file.split('_')[1])\n",
    "\n",
    "            imarr = np.load(f\"{path}\\\\{file}\")\n",
    "            im = ax.imshow(imarr, cmap=\"inferno\")\n",
    "            ax.set_title('J/J$_{sc}$ ='+f' {J_led}')\n",
    "            cbar = plt.colorbar(im,pad=0.01,aspect=20)\n",
    "            cbar.set_label('V$_{oc}$ (V)', rotation=270,labelpad=25)\n",
    "\n",
    "            scalebar_size = 0.1 # cm\n",
    "            scalebar_offset = 10 # pix\n",
    "\n",
    "            scalebar_width_pix = 0.1*pixels_per_cm\n",
    "            scalebar_height_pix = scalebar_width_pix/10\n",
    "            scalbar_y_position = imarr.shape[0]-scalebar_offset-scalebar_height_pix\n",
    "\n",
    "            text_x = scalebar_offset + scalebar_width_pix/2\n",
    "            text_y = scalbar_y_position\n",
    "\n",
    "            scalebar = patches.Rectangle((scalebar_offset,scalbar_y_position),scalebar_width_pix,scalebar_height_pix,linewidth=1,edgecolor='k',facecolor='white')\n",
    "            ax.add_patch(scalebar)\n",
    "            txt = plt.text(text_x,text_y,\"1 mm\", color = \"white\", ha='center', va='bottom', fontweight='bold')\n",
    "            txt.set_path_effects([PathEffects.withStroke(linewidth=1.2, foreground='k')])\n",
    "\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.savefig(f\"{path}\\\\{savefile_name}\")\n",
    "            \n",
    "            plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-renaissance",
   "metadata": {},
   "source": [
    "#### STEP 6.2.1(opt.): Interpolate JV from before\n",
    "* You need to have ren the cell above for this to work\n",
    "* Here, for each pixel we reconstruct a JV curve from before, and construct a bunch of images at constant voltage along the JV curve, mapping spatial current\n",
    "* THIS TAKES A LONG TIME TO RUN!!! Took 1/2 hour per pixel on 9th gen i7, 8 cores (utalising parallel processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in path_db.keys():\n",
    "    for pix in path_db[key]:     \n",
    "        path = f\"{savepath}\\\\{key}\\\\{pix}\"\n",
    "        jv_extrapolator(path, num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-pennsylvania",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run this to save the images\n",
    "for key in path_db.keys():\n",
    "    for pix in path_db[key]:\n",
    "        path = f\"{savepath}\\\\{key}\\\\{pix}\\\\V_inter\"\n",
    "        files = find_npy(path)\n",
    "\n",
    "        for file in files:\n",
    "            fig, ax = plt.subplots()\n",
    "            v = '.'.join(file.split('.')[:-1])\n",
    "\n",
    "            imarr = np.load(f\"{path}\\\\{file}\")\n",
    "            im = ax.imshow(imarr, cmap=\"inferno\")\n",
    "            ax.set_title(f'V={v}')\n",
    "            cbar = plt.colorbar(im,pad=0.01,aspect=20)\n",
    "            cbar.set_label('J/<J${sc}$>', rotation=270,labelpad=25)\n",
    "\n",
    "            scalebar_size = 0.1 # cm\n",
    "            scalebar_offset = 10 # pix\n",
    "\n",
    "            scalebar_width_pix = 0.1*pixels_per_cm\n",
    "            scalebar_height_pix = scalebar_width_pix/10\n",
    "            scalbar_y_position = imarr.shape[0]-scalebar_offset-scalebar_height_pix\n",
    "\n",
    "            text_x = scalebar_offset + scalebar_width_pix/2\n",
    "            text_y = scalbar_y_position\n",
    "\n",
    "            scalebar = patches.Rectangle((scalebar_offset,scalbar_y_position),scalebar_width_pix,scalebar_height_pix,linewidth=1,edgecolor='k',facecolor='white')\n",
    "            ax.add_patch(scalebar)\n",
    "            txt = plt.text(text_x,text_y,\"1 mm\", color = \"white\", ha='center', va='bottom', fontweight='bold')\n",
    "            txt.set_path_effects([PathEffects.withStroke(linewidth=1.2, foreground='k')])\n",
    "\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.savefig(f\"{path}\\\\{v}.png\")\n",
    "            plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
